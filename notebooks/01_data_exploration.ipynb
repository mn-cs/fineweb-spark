{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5c583c-4741-484c-a24c-e1e235efb3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq pyspark matplotlib\n",
    "import os\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4449ce-c73b-49bd-be39-2332edf12979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 000_00000.parquet (Already exists)\n",
      "Skipping 001_00000.parquet (Already exists)\n",
      "Skipping 002_00000.parquet (Already exists)\n",
      "Skipping 003_00000.parquet (Already exists)\n",
      "Skipping 004_00000.parquet (Already exists)\n",
      "Skipping 005_00000.parquet (Already exists)\n",
      "Skipping 006_00000.parquet (Already exists)\n",
      "Skipping 007_00000.parquet (Already exists)\n",
      "Skipping 008_00000.parquet (Already exists)\n",
      "Skipping 009_00000.parquet (Already exists)\n",
      "Skipping 010_00000.parquet (Already exists)\n",
      "Skipping 011_00000.parquet (Already exists)\n",
      "Skipping 012_00000.parquet (Already exists)\n",
      "Skipping 013_00000.parquet (Already exists)\n",
      "All 14 sample files downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Set the target directory to '../data' relative to the notebook\n",
    "data_dir = \"../data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Base URL for the 10BT Sample\n",
    "base_url = \"https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu/resolve/main/sample/10BT\"\n",
    "\n",
    "# Loop through files 000 to 013\n",
    "for i in range(14):\n",
    "    filename = f\"{i:03d}_00000.parquet\"\n",
    "    save_path = os.path.join(data_dir, filename)\n",
    "    \n",
    "    # Only download if missing\n",
    "    if not os.path.exists(save_path):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        !wget -q -O {save_path} {base_url}/{filename}\n",
    "    else:\n",
    "        print(f\"Skipping {filename} (Already exists)\")\n",
    "\n",
    "print(\"All 14 sample files downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b270b1e0-eb68-4f6c-aa0d-61ffe32db96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://exp-3-08.expanse.sdsc.edu:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1555319aca50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create SparkSession with specified configurations\n",
    "\n",
    "# Driver memory = 1 - 2GB (fixed, small) => 2\n",
    "# Executor memory = (Total Memory - Driver Memory) / Executor Instances => floor((128 - 2) / 7) = 18\n",
    "# Executor instances = Total Cores - 1 => 8 - 1 = 7\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memory\", \"18g\") \\\n",
    "    .config(\"spark.executor.instances\", 7) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef37498-7c0d-49fa-8a07-053fe6f2d53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all parquet files from the '../data' directory into a single DataFrame\n",
    "df = spark.read.parquet(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35dea1dd-1d68-4b5e-83d5-49f053627169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- dump: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- file_path: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- language_score: double (nullable = true)\n",
      " |-- token_count: long (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- int_score: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the schema of the DataFrame to verify it loaded correctly\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a653331-cd21-4674-a0d7-6843964d045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 9,672,101\n",
      "CPU times: user 1.17 ms, sys: 159 µs, total: 1.32 ms\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Total number of rows\n",
    "print(f\"Total rows: {df.count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b44fd63-6c37-459f-837e-eb65b8045de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions: 213\n",
      "CPU times: user 553 µs, sys: 59 µs, total: 612 µs\n",
      "Wall time: 370 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# How many partitions Spark created (affects parallelism)\n",
    "print(f\"Number of partitions: {df.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b1884-f5d1-4381-b186-e3bd8024423e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
